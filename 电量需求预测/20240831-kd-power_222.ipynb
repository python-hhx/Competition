{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:32:40.356999Z","iopub.status.busy":"2024-07-23T01:32:40.356549Z","iopub.status.idle":"2024-07-23T01:32:45.189654Z","shell.execute_reply":"2024-07-23T01:32:45.187956Z","shell.execute_reply.started":"2024-07-23T01:32:40.356963Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import lightgbm as lgb\n","import xgboost as xgb\n","import catboost as cat\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.preprocessing import LabelEncoder\n","import time\n","from tqdm import tqdm\n","import gc\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:32:49.190525Z","iopub.status.busy":"2024-07-23T01:32:49.189495Z","iopub.status.idle":"2024-07-23T01:32:50.821643Z","shell.execute_reply":"2024-07-23T01:32:50.820285Z","shell.execute_reply.started":"2024-07-23T01:32:49.190484Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv('./dataset/train.csv')\n","test = pd.read_csv('./dataset/test.csv')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:32:52.591179Z","iopub.status.busy":"2024-07-23T01:32:52.590768Z","iopub.status.idle":"2024-07-23T01:32:55.536656Z","shell.execute_reply":"2024-07-23T01:32:55.534610Z","shell.execute_reply.started":"2024-07-23T01:32:52.591148Z"},"trusted":true},"outputs":[],"source":["# 合并训练数据和测试数据，并进行排序\n","data = pd.concat([test, train], axis=0, ignore_index=True)\n","data = data.sort_values(['id','dt'], ascending=False).reset_index(drop=True)\n","\n","data['target'] = data['target'].apply(lambda x:0 if x<0 else x)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:32:56.700985Z","iopub.status.busy":"2024-07-23T01:32:56.700540Z","iopub.status.idle":"2024-07-23T01:32:56.825208Z","shell.execute_reply":"2024-07-23T01:32:56.823899Z","shell.execute_reply.started":"2024-07-23T01:32:56.700951Z"},"trusted":true},"outputs":[{"data":{"text/plain":["22"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["del train\n","del test \n","\n","gc.collect()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:32:59.838202Z","iopub.status.busy":"2024-07-23T01:32:59.837263Z","iopub.status.idle":"2024-07-23T01:32:59.846396Z","shell.execute_reply":"2024-07-23T01:32:59.844637Z","shell.execute_reply.started":"2024-07-23T01:32:59.838141Z"},"trusted":true},"outputs":[],"source":["import time\n","\n","def timer(func):\n","    def wrapper(*args, **kwargs):\n","        start_time = time.time()\n","        result = func(*args, **kwargs)\n","        end_time = time.time()\n","        print(f\"{func.__name__} took {end_time - start_time:.2f} seconds to execute.\")\n","        return result\n","    return wrapper"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["dt feature\n"]}],"source":["print(\"dt feature\")  \n","for day in [7,30,90,180,365]:\n","    data[f'sin_dt_{day}'] = np.sin(2*np.pi*data['dt']/day)\n","    data[f'cos_dt_{day}'] = np.cos(2*np.pi*data['dt']/day)\n","    \n","for gap in [2,4,7,15,30,60]:\n","    \"\"\"\n","    https://zhuanlan.zhihu.com/p/696298733\n","    正弦和余弦来自单位圆，可以映射时间戳在这个圆上的位置，用正弦和余弦坐标表示。将圆圈的右侧视为起点(在下面的图表中以0表示)或真正的24小时时间刻度上的00:00 (12AM)，我们将其划分为4个6小时的地标，以便能够将小时映射到圆上。\n","    \"\"\"\n","    for col in ['sin_dt_7','cos_dt_7','sin_dt_30','cos_dt_30','sin_dt_90','cos_dt_90','sin_dt_180','cos_dt_180','sin_dt_365','cos_dt_365']:\n","        data[f\"{col}_shift{gap}\"] = data.groupby(data['id'])[col].shift(gap)\n","        data[f\"{col}_gap{gap}\"] = data[col] - data[f\"{col}_shift{gap}\"]\n","        data.drop([f\"{col}_shift{gap}\"],axis=1,inplace=True)\n","\n","data['dt_dayofweek'] = data['dt']%7\n","for d in range(7):\n","    data[f'dt_dayofweek_{d}'] = (data['dt_dayofweek']==d)  \n","data['dt_month'] = data['dt']//30%12\n","for d in range(12):\n","    data[f'dt_month_{d}'] = (data['dt_month']==d)\n","data['dt_year'] = data['dt']//365"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:33:02.297065Z","iopub.status.busy":"2024-07-23T01:33:02.296536Z","iopub.status.idle":"2024-07-23T01:33:11.211952Z","shell.execute_reply":"2024-07-23T01:33:11.210795Z","shell.execute_reply.started":"2024-07-23T01:33:02.297025Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["get_shift_cols took 3.03 seconds to execute.\n"]}],"source":["@timer\n","def get_shift_cols(data, start_day, end_day):\n","    \"\"\"计算平移天数的target\"\"\"\n","    for i in range(10,30):\n","        data[f'last{i}_target'] = data.groupby(['id'])['target'].shift(i)\n","        data[f'last{i}_target_type'] = data.groupby(['type'])['target'].shift(i)\n","    return data\n","\n","data = get_shift_cols(data, 10, 31)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:33:14.231828Z","iopub.status.busy":"2024-07-23T01:33:14.231363Z","iopub.status.idle":"2024-07-23T01:34:10.428712Z","shell.execute_reply":"2024-07-23T01:34:10.427379Z","shell.execute_reply.started":"2024-07-23T01:33:14.231789Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [00:17<00:00,  8.54s/it]"]},{"name":"stdout","output_type":"stream","text":["get_diff_shift took 17.12 seconds to execute.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["@timer\n","def get_diff_shift(data, col_names, shift_days, diff_days):\n","    \"\"\"\n","    shift_days = [14]\n","    diff_days = [1,2,3]\n","    计算平移的target后再计算相应的差分\n","    \"\"\"\n","    for col_ in tqdm(col_names):\n","        for s_days in shift_days:\n","            for d_days in diff_days:\n","                data['d_{}_{}_before_diff'.format(s_days, d_days)] = data.groupby(col_)['target'].shift(s_days).diff(d_days)\n","    return data\n","\n","data = get_diff_shift(data, ['id', 'type'], [i for i in range(14, 30)], [i for i in range(1, 8)])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:38:25.068724Z","iopub.status.busy":"2024-07-23T01:38:25.068256Z","iopub.status.idle":"2024-07-23T01:38:49.982154Z","shell.execute_reply":"2024-07-23T01:38:49.980913Z","shell.execute_reply.started":"2024-07-23T01:38:25.068689Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 1/6 [01:13<06:08, 73.64s/it]"]},{"name":"stdout","output_type":"stream","text":["get_win_mean_target took 73.63 seconds to execute.\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 2/6 [02:43<05:33, 83.46s/it]"]},{"name":"stdout","output_type":"stream","text":["get_win_mean_target took 90.31 seconds to execute.\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 3/6 [04:20<04:27, 89.28s/it]"]},{"name":"stdout","output_type":"stream","text":["get_win_mean_target took 96.19 seconds to execute.\n"]},{"name":"stderr","output_type":"stream","text":[" 67%|██████▋   | 4/6 [06:00<03:07, 93.59s/it]"]},{"name":"stdout","output_type":"stream","text":["get_win_mean_target took 100.18 seconds to execute.\n"]},{"name":"stderr","output_type":"stream","text":[" 83%|████████▎ | 5/6 [07:45<01:37, 97.87s/it]"]},{"name":"stdout","output_type":"stream","text":["get_win_mean_target took 105.44 seconds to execute.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [09:27<00:00, 94.52s/it]"]},{"name":"stdout","output_type":"stream","text":["get_win_mean_target took 101.27 seconds to execute.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["@timer\n","def get_win_mean_target(data, start_day, end_day):\n","    col_list = ['last{}_target'.format(i) for i in range(start_day, end_day)]\n","    col_name = end_day - start_day\n","    data['win{}_mean_target'.format(col_name)] = data[col_list].mean(axis=1)\n","    data['win{}_median_target'.format(col_name)] = data[col_list].median(axis=1)\n","    data['win{}_min_target'.format(col_name)] = data[col_list].min(axis=1)\n","    data['win{}_max_target'.format(col_name)] = data[col_list].max(axis=1)\n","    return data\n","\n","for i in tqdm(range(12, 18)):\n","    data = get_win_mean_target(data, 10, i)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:39:28.343436Z","iopub.status.busy":"2024-07-23T01:39:28.342416Z","iopub.status.idle":"2024-07-23T01:39:31.451928Z","shell.execute_reply":"2024-07-23T01:39:31.450630Z","shell.execute_reply.started":"2024-07-23T01:39:28.343394Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["get_groupby_col took 154.42 seconds to execute.\n","get_groupby_col took 158.16 seconds to execute.\n"]}],"source":["@timer\n","def get_groupby_col(data, col_name):\n","    data['target_mean_{}'.format(col_name)] = data.groupby(col_name)[['target']].transform(np.mean)\n","    data['target_median_{}'.format(col_name)] = data.groupby(col_name)[['target']].transform(np.median)\n","    data['target_max_{}'.format(col_name)] = data.groupby(col_name)[['target']].transform(np.max)\n","    data['target_min_{}'.format(col_name)] = data.groupby(col_name)[['target']].transform(np.min)\n","    data['target_var_{}'.format(col_name)] = data.groupby(col_name)[['target']].transform(np.var)\n","    data['target_std_{}'.format(col_name)] = data.groupby(col_name)[['target']].transform(np.std)\n","#     data[\"target_quantile_25_{}\"] = data.groupby(col_name)[['target']].transform(np.quantile(q = 0.25))\n","#     data[\"target_quantile_75_{}\"] = data.groupby(col_name)[['target']].transform(np.quantile(q = 0.75))\n","    return data\n","data = get_groupby_col(data, 'id')\n","data = get_groupby_col(data, 'type')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:39:35.228382Z","iopub.status.busy":"2024-07-23T01:39:35.227939Z","iopub.status.idle":"2024-07-23T01:40:49.452923Z","shell.execute_reply":"2024-07-23T01:40:49.451411Z","shell.execute_reply.started":"2024-07-23T01:39:35.228330Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["get_groupby_col_by_days took 206.07 seconds to execute.\n","get_groupby_col_by_days took 203.66 seconds to execute.\n"]}],"source":["@timer\n","def get_groupby_col_by_days(data, col_name, days):\n","    data_target_mean = data[data['dt']<=days].groupby(col_name)['target'].mean().reset_index()\n","    data_target_median = data[data['dt']<=days].groupby(col_name)['target'].median().reset_index()\n","    data_target_max = data[data['dt']<=days].groupby(col_name)['target'].max().reset_index()\n","    data_target_min = data[data['dt']<=days].groupby(col_name)['target'].min().reset_index()\n","    data_target_var = data[data['dt']<=days].groupby(col_name)['target'].var().reset_index()\n","    data_target_std = data[data['dt']<=days].groupby(col_name)['target'].std().reset_index()\n","\n","    data_target_mean.rename(columns={'target': 'target_mean_{}_{}'.format(days, col_name)}, inplace=True)\n","    data_target_median.rename(columns={'target': 'target_median_{}_{}'.format(days, col_name)}, inplace=True)\n","    data_target_max.rename(columns={'target': 'target_max_{}_{}'.format(days, col_name)}, inplace=True)\n","    data_target_min.rename(columns={'target': 'target_min_{}_{}'.format(days, col_name)}, inplace=True)\n","    data_target_var.rename(columns={'target': 'target_var_{}_{}'.format(days, col_name)}, inplace=True)\n","    data_target_std.rename(columns={'target': 'target_std_{}_{}'.format(days, col_name)}, inplace=True)\n","\n","    data = data.merge(data_target_mean, on=[col_name], how='left')\n","    data = data.merge(data_target_median, on=[col_name], how='left')\n","    data = data.merge(data_target_max, on=[col_name], how='left')\n","    data = data.merge(data_target_min, on=[col_name], how='left')\n","    data = data.merge(data_target_var, on=[col_name], how='left')\n","    data = data.merge(data_target_std, on=[col_name], how='left')\n","    return data\n","\n","data = get_groupby_col_by_days(data, 'id', 20)\n","data = get_groupby_col_by_days(data, 'id', 30)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:41:01.005661Z","iopub.status.busy":"2024-07-23T01:41:01.004480Z","iopub.status.idle":"2024-07-23T01:41:01.202326Z","shell.execute_reply":"2024-07-23T01:41:01.201006Z","shell.execute_reply.started":"2024-07-23T01:41:01.005603Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["get_target_speed_rate took 0.28 seconds to execute.\n"]}],"source":["@timer\n","def get_target_speed_rate(data, start_day, end_day):\n","    for num in range(start_day, end_day+1):\n","        a_df = data['last{}_target'.format(num)] \n","        b_df = data['last{}_target'.format(num+1)]\n","        data['last_{}_{}_speed_rate'.format(num, num+1)] = (a_df - b_df) / (b_df + 0.0001)\n","    return data\n","\n","data = get_target_speed_rate(data, 10, 17)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:41:03.938692Z","iopub.status.busy":"2024-07-23T01:41:03.937459Z","iopub.status.idle":"2024-07-23T01:41:04.483784Z","shell.execute_reply":"2024-07-23T01:41:04.482277Z","shell.execute_reply.started":"2024-07-23T01:41:03.938638Z"},"trusted":true},"outputs":[],"source":["label_encode = LabelEncoder() \n","data['id_label'] = label_encode.fit_transform(data['id'])"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:41:13.374966Z","iopub.status.busy":"2024-07-23T01:41:13.374537Z","iopub.status.idle":"2024-07-23T01:41:24.104440Z","shell.execute_reply":"2024-07-23T01:41:24.103078Z","shell.execute_reply.started":"2024-07-23T01:41:13.374933Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:03<00:00,  2.24it/s]\n"]}],"source":["from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","import warnings\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import seaborn as sns\n","\n","warnings.filterwarnings('ignore')\n","\n","df_for_kmean = data[['id', 'type', 'target_mean_id', 'target_median_id', 'target_max_id', 'target_min_id', 'target_var_id', 'target_std_id']]\n","df_for_kmean.set_index('id', inplace=True)\n","df_for_kmean.drop_duplicates(inplace=True)\n","\n","k_values = range(2, 10)\n","evaluation_k = []\n","evaluation_score = []\n","\n","\"\"\"\n","Silhouette分数的取值范围在[-1, 1]之间，分数越接近1表示聚类效果越好\n","\"\"\"\n","# 遍历不同的K值\n","for k in tqdm(k_values):\n","    kmeans = KMeans(n_clusters=k, random_state=2024)\n","    cluster_labels = kmeans.fit_predict(df_for_kmean)\n","    \n","    # 计算Silhouette Score\n","    silhouette = silhouette_score(df_for_kmean, cluster_labels)\n","    # 将评估指标值保存下来\n","    evaluation_k.append(k)\n","    evaluation_score.append(silhouette)\n","\n","best_k = 4\n","kmeans_best = KMeans(n_clusters=best_k, random_state=2024)\n","cluster_labels = kmeans_best.fit_predict(df_for_kmean)\n","df_for_kmean['kmeans_label'] = cluster_labels\n","\n","data_kmeans_labels = kmeans_best.predict(data[['type', 'target_mean_id', 'target_median_id', 'target_max_id', 'target_min_id', 'target_var_id', 'target_std_id']])"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:41:40.813101Z","iopub.status.busy":"2024-07-23T01:41:40.812143Z","iopub.status.idle":"2024-07-23T01:42:06.575376Z","shell.execute_reply":"2024-07-23T01:42:06.574252Z","shell.execute_reply.started":"2024-07-23T01:41:40.813050Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [00:16<00:00,  8.45s/it]\n"]}],"source":["data['kmeans_labels'] = data_kmeans_labels\n","\n","data['target_mean_kmeanslabels'] = data.groupby('kmeans_labels')[['target']].transform(np.mean)\n","data['target_median_kmeanslabels'] = data.groupby('kmeans_labels')[['target']].transform(np.median)\n","data['target_max_kmeanslabels'] = data.groupby('kmeans_labels')[['target']].transform(np.max)\n","data['target_min_kmeanslabels'] = data.groupby('kmeans_labels')[['target']].transform(np.min)\n","data['target_var_kmeanslabels'] = data.groupby('kmeans_labels')[['target']].transform(np.var)\n","data['target_std_kmeanslabels'] = data.groupby('kmeans_labels')[['target']].transform(np.std)\n","\n","for i in tqdm(range(11, 13)):\n","    for i1 in range(3, 8):\n","        data['d_{}_before_diff_rolling_mean_{}'.format(i, i1)] = data.groupby('id')['target'].shift(i).rolling(i1).mean()\n","        data['d_{}_before_diff_rolling_median_{}'.format(i, i1)] = data.groupby('id')['target'].shift(i).rolling(i1).median()\n","        data['d_{}_before_diff_rolling_max_{}'.format(i, i1)] = data.groupby('id')['target'].shift(i).rolling(i1).max()\n","        data['d_{}_before_diff_rolling_min_{}'.format(i, i1)] = data.groupby('id')['target'].shift(i).rolling(i1).min()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:45:06.111523Z","iopub.status.busy":"2024-07-23T01:45:06.111083Z","iopub.status.idle":"2024-07-23T01:45:12.284038Z","shell.execute_reply":"2024-07-23T01:45:12.282931Z","shell.execute_reply.started":"2024-07-23T01:45:06.111488Z"},"trusted":true},"outputs":[],"source":["# 进行数据切分\n","data = data.loc[data['dt']<500]\n","train = data[data.target.notnull()].reset_index(drop=True)\n","test = data[data.target.isnull()].reset_index(drop=True)\n","\n","train_cols = [f for f in train.columns if f not in ['id','target']]"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T01:45:18.498749Z","iopub.status.busy":"2024-07-23T01:45:18.498292Z","iopub.status.idle":"2024-07-23T01:45:18.845863Z","shell.execute_reply":"2024-07-23T01:45:18.844538Z","shell.execute_reply.started":"2024-07-23T01:45:18.498713Z"},"trusted":true},"outputs":[],"source":["del data\n","gc.collect()"]},{"cell_type":"code","execution_count":20,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"source":["# \"\"\"\n","# 在原先衍生0715号的特征基础上又继续衍生后，导致线上的特征下滑，猜测可能特征上出现了过拟合的现象\n","# 在此进行相关的特征剔除，使用null importance进行特征过滤\n","# \"\"\"\n","# from sklearn.metrics import mean_squared_error\n","\n","# def get_feature_importances(data, shuffle):\n","#     # Gather real features\n","#     train_features = [f for f in data.columns if f not in ['id','target']]\n","#     # Go over fold and keep track of CV score (train and valid) and feature importances\n","    \n","#     data_copy = data.copy()\n","\n","#     del data\n","#     gc.collect()\n","\n","#     # Shuffle target if required\n","#     if shuffle:\n","#         # Here you could as well use a binomial distribution\n","#         y = data_copy['target'].copy().sample(frac=1.0)\n","#         data_copy['target'] = y.tolist()\n","\n","#     imp_df = pd.DataFrame()\n","\n","#     trn_x, trn_y = data_copy.loc[(data_copy['dt']>=31)][train_features], data_copy.loc[(data_copy['dt']>=31)]['target']\n","#     val_x, val_y = data_copy.loc[(data_copy['dt']<=30)][train_features], data_copy.loc[(data_copy['dt']<=30)]['target']\n","#     # 构建模型输入数据\n","#     train_matrix = lgb.Dataset(trn_x, label=trn_y)\n","#     valid_matrix = lgb.Dataset(val_x, label=val_y)\n","\n","#     # lightgbm参数\n","#     lgb_params = {\n","#         'boosting_type': 'gbdt',\n","#         'objective': 'regression',\n","#         'metric': 'mse',\n","#         'min_child_weight': 5,\n","#         'num_leaves': 2 ** 5,\n","#         'lambda_l2': 10,\n","#         'feature_fraction': 0.8,\n","#         'bagging_fraction': 0.8,\n","#         'bagging_freq': 4,\n","#         'learning_rate': 0.05,\n","#         'seed': 2024,\n","#         'nthread' : 16,\n","#         'verbose' : -1,\n","#     }\n","#         # 训练模型\n","#     model_null_importance = lgb.train(lgb_params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], \n","#                         callbacks=[lgb.early_stopping(stopping_rounds=500), lgb.log_evaluation(500)])\n","        \n","#     # Get feature importances\n","#     imp_df = pd.DataFrame()\n","#     imp_df[\"feature\"] = list(train_features)\n","#     imp_df[\"importance_gain\"] = model_null_importance.feature_importance(importance_type='gain')\n","#     imp_df[\"importance_split\"] = model_null_importance.feature_importance(importance_type='split')\n","#     imp_df['trn_score'] = mean_squared_error(data_copy['target'].tolist(), model_null_importance.predict(data_copy[train_features]))\n","#     return imp_df\n","\n","# use_df = train\n","# # null importance 变量\n","# null_imp_df = pd.DataFrame()\n","# # 运行次数50次\n","# nb_runs = 10\n","# # 标签数据\n","# label = 'target'\n","# # 真实响应变量下的特征重要度\n","# actual_imp_df = get_feature_importances(data=use_df, shuffle=False)\n","\n","# import time\n","# start = time.time()\n","\n","# dsp = ''\n","# # 运算Null importance\n","# for i in range(nb_runs):\n","#     # Get current run importances\n","#     imp_df = get_feature_importances(data=use_df, shuffle=True)\n","#     imp_df['run'] = i + 1 \n","#     # Concat the latest importances with the old ones\n","#     null_imp_df = pd.concat([null_imp_df, imp_df], axis=0)\n","#     # Erase previous message\n","#     for l in range(len(dsp)):\n","#         print('\\b', end='', flush=True)\n","#     # Display current run and time used\n","#     spent = (time.time() - start) / 60\n","#     dsp = 'Done with %4d of %4d (Spent %5.1f min)' % (i + 1, nb_runs, spent)\n","#     print(dsp, end='', flush=True)\n","\n","# feature_scores = []\n","# for _f in actual_imp_df['feature'].unique():\n","#     f_null_imps_gain = null_imp_df.loc[null_imp_df['feature'] == _f, 'importance_gain'].values\n","#     f_act_imps_gain = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'importance_gain'].mean()\n","#     gain_score = np.log(1e-10 + f_act_imps_gain / (1 + np.percentile(f_null_imps_gain, 75)))  # Avoid didvide by zero\n","#     f_null_imps_split = null_imp_df.loc[null_imp_df['feature'] == _f, 'importance_split'].values\n","#     f_act_imps_split = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'importance_split'].mean()\n","#     split_score = np.log(1e-10 + f_act_imps_split / (1 + np.percentile(f_null_imps_split, 75)))  # Avoid didvide by zero\n","#     feature_scores.append((_f, split_score, gain_score))\n","\n","# scores_df = pd.DataFrame(feature_scores, columns=['feature', 'split_score', 'gain_score'])\n","\n","# feats = scores_df['feature'][(scores_df['split_score']>0) & (scores_df['gain_score']>0)].tolist()\n","\n","# \"\"\"\n","# 所有特征都可以满足\n","# \"\"\""]},{"cell_type":"markdown","metadata":{},"source":["# 参数优化"]},{"cell_type":"code","execution_count":21,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"source":["# import optuna\n","# from optuna.samplers import TPESampler\n","# from sklearn.metrics import mean_squared_error\n","\n","# class OptunaSingel:\n","\n","#     def __init__(self, state, ntrials, metric_obj, data, model_type, cols):\n","#         self.random_state = state\n","#         self.n_trials = ntrials\n","#         self.best_weight = None\n","#         self.direction = metric_obj\n","#         self.data = data\n","#         self.model_type = model_type\n","#         self.cols = cols\n","\n","#     def _objective(self, trial):\n","#         score_list = []\n","#         if self.model_type == 'lgb':\n","#             lgb_params = {\n","#                 'boosting_type': 'gbdt',\n","#                 'objective': 'regression',\n","#                 'metric': 'mse',\n","#                 'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n","#                 'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n","#                 'lambda_l2': trial.suggest_int('lambda_l2', 1, 20),\n","#                 'feature_fraction': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n","#                 'bagging_fraction': trial.suggest_uniform('subsample', 0, 1.0),\n","#                 'bagging_freq': trial.suggest_int('subsample_freq', 1, 10),\n","#                 'learning_rate': trial.suggest_discrete_uniform('learning_rate',0.0,1.0,0.01),\n","#                 'seed': 2024,\n","#                 'verbose' : -1,\n","#             }\n","            \n","#         start_time = 20\n","#         end_time = 30\n","#         gap_time = 10\n","#         for i in range(start_time, end_time, gap_time):\n","#         # 训练集和验证集切分\n","#             trn_x, trn_y = data.loc[(data['dt']>=i+1)][self.cols], data.loc[(data['dt']>=i+1)]['target']\n","#             val_x, val_y = data.loc[(data['dt']<=i)][self.cols], data.loc[(data['dt']<=i)]['target']\n","#             if self.model_type == 'lgb':\n","#                 train_matrix = lgb.Dataset(trn_x, label=trn_y)\n","#                 valid_matrix = lgb.Dataset(val_x, label=val_y)\n","\n","#             model = lgb.train(lgb_params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix])\n","#             val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n","#             score = mean_squared_error(val_y, val_pred)\n","#             score_list.append(score)\n","#         return np.mean(score_list)\n","\n","#     def fit(self):\n","#         self.study = optuna.create_study(direction=self.direction, sampler=TPESampler(seed=self.random_state))\n","#         self.study.optimize(self._objective, n_trials=self.n_trials)\n","#         self.best_weight = self.study.best_params\n","\n","#     def weight(self):\n","#         return self.best_weight\n","    \n","# obj_opt = OptunaSingel(state=2024, \n","#                        ntrials=500, \n","#                        metric_obj='minimize', \n","#                        data=train, \n","#                        model_type='lgb', \n","#                        cols=train_cols)\n","# obj_opt.fit()"]},{"cell_type":"code","execution_count":22,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-07-23T01:45:34.701978Z","iopub.status.busy":"2024-07-23T01:45:34.701521Z","iopub.status.idle":"2024-07-23T01:52:55.098898Z","shell.execute_reply":"2024-07-23T01:52:55.097401Z","shell.execute_reply.started":"2024-07-23T01:45:34.701942Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------正在进行lgb模型训练--------------------\n","Training until validation scores don't improve for 500 rounds\n","[500]\ttraining's l2: 129.19\tvalid_1's l2: 149.721\n","[1000]\ttraining's l2: 114.432\tvalid_1's l2: 142.703\n","[1500]\ttraining's l2: 105.409\tvalid_1's l2: 139.126\n","[2000]\ttraining's l2: 99.2082\tvalid_1's l2: 137.028\n","[2500]\ttraining's l2: 94.0693\tvalid_1's l2: 135.142\n","[3000]\ttraining's l2: 90.106\tvalid_1's l2: 133.585\n","[3500]\ttraining's l2: 86.8255\tvalid_1's l2: 132.312\n","[4000]\ttraining's l2: 84.0066\tvalid_1's l2: 131.518\n","[4500]\ttraining's l2: 81.5009\tvalid_1's l2: 130.511\n","[5000]\ttraining's l2: 79.3018\tvalid_1's l2: 128.957\n","[5500]\ttraining's l2: 77.29\tvalid_1's l2: 127.636\n","[6000]\ttraining's l2: 75.5187\tvalid_1's l2: 127.505\n","[6500]\ttraining's l2: 73.8015\tvalid_1's l2: 127.102\n","[7000]\ttraining's l2: 72.2324\tvalid_1's l2: 126.383\n","[7500]\ttraining's l2: 70.8188\tvalid_1's l2: 126.166\n","[8000]\ttraining's l2: 69.544\tvalid_1's l2: 125.854\n","[8500]\ttraining's l2: 68.3052\tvalid_1's l2: 125.463\n","[9000]\ttraining's l2: 67.1726\tvalid_1's l2: 125.296\n","[9500]\ttraining's l2: 66.0461\tvalid_1's l2: 125.074\n","[10000]\ttraining's l2: 65.0193\tvalid_1's l2: 124.89\n","[10500]\ttraining's l2: 64.063\tvalid_1's l2: 124.845\n","[11000]\ttraining's l2: 63.1522\tvalid_1's l2: 124.875\n","Early stopping, best iteration is:\n","[10747]\ttraining's l2: 63.6052\tvalid_1's l2: 124.803\n","124.80349564314386\n","Training until validation scores don't improve for 500 rounds\n","[500]\ttraining's l2: 129.366\tvalid_1's l2: 144.692\n","[1000]\ttraining's l2: 114.31\tvalid_1's l2: 140.668\n","[1500]\ttraining's l2: 105.232\tvalid_1's l2: 138.147\n","[2000]\ttraining's l2: 98.8826\tvalid_1's l2: 136.053\n","[2500]\ttraining's l2: 93.9446\tvalid_1's l2: 135.011\n","[3000]\ttraining's l2: 90.1361\tvalid_1's l2: 133.521\n","[3500]\ttraining's l2: 86.7705\tvalid_1's l2: 132.447\n","[4000]\ttraining's l2: 83.912\tvalid_1's l2: 132.048\n","[4500]\ttraining's l2: 81.4267\tvalid_1's l2: 131.491\n","[5000]\ttraining's l2: 79.153\tvalid_1's l2: 130.826\n","[5500]\ttraining's l2: 77.1928\tvalid_1's l2: 130.787\n","[6000]\ttraining's l2: 75.4126\tvalid_1's l2: 130.37\n","[6500]\ttraining's l2: 73.748\tvalid_1's l2: 130.226\n","[7000]\ttraining's l2: 72.2238\tvalid_1's l2: 130.013\n","[7500]\ttraining's l2: 70.8058\tvalid_1's l2: 129.832\n","[8000]\ttraining's l2: 69.5258\tvalid_1's l2: 129.443\n","[8500]\ttraining's l2: 68.3111\tvalid_1's l2: 129.271\n","[9000]\ttraining's l2: 67.1435\tvalid_1's l2: 129.167\n","[9500]\ttraining's l2: 66.0389\tvalid_1's l2: 129.067\n","[10000]\ttraining's l2: 64.9362\tvalid_1's l2: 128.731\n","[10500]\ttraining's l2: 63.9427\tvalid_1's l2: 128.647\n","[11000]\ttraining's l2: 62.962\tvalid_1's l2: 128.342\n","[11500]\ttraining's l2: 62.0502\tvalid_1's l2: 128.337\n","[12000]\ttraining's l2: 61.2021\tvalid_1's l2: 128.278\n","[12500]\ttraining's l2: 60.3746\tvalid_1's l2: 128.214\n","[13000]\ttraining's l2: 59.579\tvalid_1's l2: 128.125\n","[13500]\ttraining's l2: 58.7947\tvalid_1's l2: 128.076\n","[14000]\ttraining's l2: 58.064\tvalid_1's l2: 128.028\n","[14500]\ttraining's l2: 57.3419\tvalid_1's l2: 128.014\n","Early stopping, best iteration is:\n","[14311]\ttraining's l2: 57.613\tvalid_1's l2: 128.001\n","128.00107574967137\n","Training until validation scores don't improve for 500 rounds\n","[500]\ttraining's l2: 129.003\tvalid_1's l2: 160.562\n","[1000]\ttraining's l2: 113.972\tvalid_1's l2: 156.938\n","[1500]\ttraining's l2: 105.121\tvalid_1's l2: 153.701\n","[2000]\ttraining's l2: 98.5521\tvalid_1's l2: 152.119\n","[2500]\ttraining's l2: 93.5007\tvalid_1's l2: 150.818\n","[3000]\ttraining's l2: 89.533\tvalid_1's l2: 149.753\n","[3500]\ttraining's l2: 86.2567\tvalid_1's l2: 149.253\n","[4000]\ttraining's l2: 83.3725\tvalid_1's l2: 148.739\n","[4500]\ttraining's l2: 80.9034\tvalid_1's l2: 148.222\n","[5000]\ttraining's l2: 78.6444\tvalid_1's l2: 147.974\n","[5500]\ttraining's l2: 76.7086\tvalid_1's l2: 147.865\n","[6000]\ttraining's l2: 74.9439\tvalid_1's l2: 147.515\n","[6500]\ttraining's l2: 73.2867\tvalid_1's l2: 147.299\n","[7000]\ttraining's l2: 71.7744\tvalid_1's l2: 147.126\n","[7500]\ttraining's l2: 70.3894\tvalid_1's l2: 146.957\n","[8000]\ttraining's l2: 69.0524\tvalid_1's l2: 146.855\n","Early stopping, best iteration is:\n","[7751]\ttraining's l2: 69.7157\tvalid_1's l2: 146.804\n","146.80425302515312\n","[124.80349564314386, 128.00107574967137, 146.80425302515312]\n","133.2029414726561\n","CPU times: user 15h 28min 56s, sys: 3h 1min 1s, total: 18h 29min 57s\n","Wall time: 3h 1min 45s\n"]}],"source":["%%time\n","\n","from sklearn.metrics import mean_squared_error\n","\n","fea_imp_dict = {}\n","\n","def lgb_model(clf, train_df, test_df, cols):\n","    print('--------------------正在进行lgb模型训练--------------------')\n","    score_list = []\n","    test_oof = np.zeros(len(test_df))\n","\n","    start_time = 20\n","    end_time = 50\n","    gap_time = 10\n","\n","    for i in range(start_time, end_time, gap_time):\n","    # 训练集和验证集切分\n","        trn_x, trn_y = train_df.loc[(train_df['dt']>=i+1)][cols], train_df.loc[(train_df['dt']>=i+1)]['target']\n","        val_x, val_y = train_df.loc[(train_df['dt']<=i)][cols], train_df.loc[(train_df['dt']<=i)]['target']\n","        # 构建模型输入数据\n","        train_matrix = clf.Dataset(trn_x, label=trn_y)\n","        valid_matrix = clf.Dataset(val_x, label=val_y)\n","        # lightgbm参数\n","        lgb_params = {\n","            'boosting_type': 'gbdt',\n","            'objective': 'regression',\n","            'metric': 'mse',\n","            'min_child_weight': 5,\n","            'num_leaves': 2 ** 5,\n","            'lambda_l2': 10,\n","            'feature_fraction': 0.8,\n","            'bagging_fraction': 0.8,\n","            'bagging_freq': 4,\n","            'learning_rate': 0.05,\n","            'seed': 2024,\n","            'nthread' : 16,\n","            'verbose' : -1,\n","        }\n","        # 训练模型\n","        model = clf.train(lgb_params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], \n","                        categorical_feature=[], callbacks=[lgb.early_stopping(stopping_rounds=500), lgb.log_evaluation(500)])\n","        # 验证集和测试集结果预测\n","        val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n","        test_pred = model.predict(test_df[cols], num_iteration=model.best_iteration)\n","        fea_imp = dict(zip(model.feature_name(), model.feature_importance()))\n","        fea_imp_dict.setdefault(str(i),fea_imp)\n","        # 离线分数评估\n","        score = mean_squared_error(val_pred, val_y)\n","        score_list.append(score)\n","        test_oof += test_pred / ((end_time - start_time)/gap_time)\n","        print(score)\n","    print(score_list)\n","    print(np.mean(score_list))\n","    return val_pred, test_oof, model\n","\n","\n","def xgb_model(clf, train_df, test_df, cols):\n","    print('--------------------正在进行xg模型训练--------------------')\n","    score_list = []\n","    test_oof = np.zeros(len(test_df))\n","\n","    start_time = 20\n","    end_time = 50\n","    gap_time = 10\n","\n","    for i in range(start_time, end_time, gap_time):\n","        trn_x, trn_y = train_df.loc[(train_df['dt']>=i+1)][cols], train_df.loc[(train_df['dt']>=i+1)]['target']\n","        val_x, val_y = train_df.loc[(train_df['dt']<=i)][cols], train_df.loc[(train_df['dt']<=i)]['target']\n","\n","        xgb_params = {\n","            'n_estimators': 30000,\n","            'learning_rate': 0.01,\n","            'booster': 'gbtree',\n","            # 'eval_metric': 'rmse',\n","            'subsample': 0.9,\n","            'colsample_bytree': 0.9,\n","            'min_child_weight': 10,\n","            'objective': 'reg:squarederror',\n","            'verbosity':0,\n","            'random_state': 2024,\n","            }\n","\n","        def custom_mse(preds, dtrain):\n","            labels = dtrain.get_label()\n","            mse = mean_squared_error(labels, preds)\n","            return 'custom_mse', mse\n","\n","        xgb_model = clf.XGBRegressor(**xgb_params)\n","        xgb_model.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], \n","                    eval_metric=custom_mse, verbose=1000, early_stopping_rounds=100)\n","\n","        # 验证集和测试集结果预测\n","        xgb_val_pred = xgb_model.predict(val_x)\n","        xgb_test_pred = xgb_model.predict(test_df[train_cols])\n","\n","        # 离线分数评估\n","        score = mean_squared_error(xgb_val_pred, val_y)\n","        score_list.append(score)\n","        test_oof += xgb_test_pred / ((end_time - start_time)/gap_time)\n","        # 离线分数评估\n","        xgb_score = mean_squared_error(xgb_val_pred, val_y)\n","        print(xgb_score)\n","\n","    print(score_list)\n","    print(np.mean(score_list))\n","    \n","    return xgb_val_pred, xgb_test_pred, xgb_model\n","\n","lgb_oof, lgb_test, model_lgb = lgb_model(lgb, train, test, train_cols)\n","# xgb_oof, xgb_test, xgb_model = xgb_model(xgb, train, test, train_cols)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-07-20T17:59:32.096052Z","iopub.status.busy":"2024-07-20T17:59:32.095511Z","iopub.status.idle":"2024-07-20T17:59:32.307244Z","shell.execute_reply":"2024-07-20T17:59:32.305743Z","shell.execute_reply.started":"2024-07-20T17:59:32.096010Z"},"trusted":true},"outputs":[],"source":["# 保存结果文件到本地\n","test['target'] = lgb_test\n","test['target'] = test['target'].apply(lambda x:0 if x<0 else x)\n","test[['id','dt','target']].to_csv('submit_0803_2_test.csv', index=None)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5412790,"sourceId":8987447,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"},"vscode":{"interpreter":{"hash":"b8f46c67735de3cde6c4760c6eac4f1a0a8affa13d104cdac18d690038b758e2"}}},"nbformat":4,"nbformat_minor":4}
